{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42f0df74",
   "metadata": {},
   "source": [
    "# This notebook contains an encoder-decoder model implementation for English to Arabic translation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvNzL9GnCWH7"
   },
   "source": [
    "Import Toolkit(Libs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a comment explaining the code\n",
    "import numpy as np\n",
    "# This is a comment explaining the code\n",
    "import pandas as pd\n",
    "# This is a comment explaining the code\n",
    "import matplotlib.pyplot as plt\n",
    "# This is a comment explaining the code\n",
    "import seaborn as sns\n",
    "# This is a comment explaining the code\n",
    "import os\n",
    "# This is a comment explaining the code\n",
    "import tensorflow as tf\n",
    "# This is a comment explaining the code\n",
    "from tensorflow import keras\n",
    "# This is a comment explaining the code\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "# This is a comment explaining the code\n",
    "from tensorflow.keras.layers import Input,Dense,Activation,LSTM,GRU,Embedding\n",
    "# This is a comment explaining the code\n",
    "from tensorflow.keras.preprocessing.text import one_hot,Tokenizer\n",
    "# This is a comment explaining the code\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzHp5Q6eENoC"
   },
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bdf622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a comment explaining the code\n",
    "df=pd.read_csv(\"ara_eng.txt\",delimiter=\"\\t\",names=[\"input\",\"target\"])\n",
    "\n",
    "# This is a comment explaining the code\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOwC7bl7FNh4"
   },
   "source": [
    "Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e610e147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert inputs to lowercase\n",
    "# This is a comment explaining the code\n",
    "df[\"input\"]=df[\"input\"].apply(lambda text:text.lower())\n",
    "\n",
    "# This is a comment explaining the code\n",
    "df.shape\n",
    "\n",
    "# This is a comment explaining the code\n",
    "df.head()\n",
    "\n",
    "# This is a comment explaining the code\n",
    "df.info()\n",
    "\n",
    "# add columns contain length for inputs and target\n",
    "# This is a comment explaining the code\n",
    "df[\"length_input\"]=df[\"input\"].apply(lambda text:len(text.split(\" \")))\n",
    "# This is a comment explaining the code\n",
    "df[\"length_target\"]=df[\"target\"].apply(lambda text:len(text.split(\" \")))\n",
    "\n",
    "# This is a comment explaining the code\n",
    "df.head()\n",
    "\n",
    "# This is a comment explaining the code\n",
    "max_input_length=np.array(df[\"length_input\"].to_list()).max()\n",
    "# This is a comment explaining the code\n",
    "max_input_length\n",
    "\n",
    "# This is a comment explaining the code\n",
    "df[df[\"length_input\"] == 225][\"input\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fintrt0WGuO8"
   },
   "source": [
    "we show there are maximum is very huge and it cause forget in cell we decide make drawing to show representation about data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56804c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a comment explaining the code\n",
    "plt.hist(df[\"length_input\"])\n",
    "\n",
    "# This is a comment explaining the code\n",
    "plt.hist(df[\"length_target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPEUiZmHIIkU"
   },
   "source": [
    "we show most sentences in this data is less than 12 words, so we delete rows which higher than 20 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e9825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a comment explaining the code\n",
    "new_data=df[df[\"length_input\"] <= 12]\n",
    "# This is a comment explaining the code\n",
    "new_data.shape\n",
    "\n",
    "# This is a comment explaining the code\n",
    "new_data.sample(10)\n",
    "\n",
    "# add tag <start> and <end> to target columns\n",
    "# This is a comment explaining the code\n",
    "df[\"target\"]=df[\"target\"].apply(lambda text:f\"<start> {text} <end>\")\n",
    "# This is a comment explaining the code\n",
    "new_data[\"target\"]=new_data[\"target\"].apply(lambda text:f\"<start> {text} <end>\")\n",
    "\n",
    "\n",
    "\n",
    "# This is a comment explaining the code\n",
    "df.head(20)\n",
    "\n",
    "# This is a comment explaining the code\n",
    "english=new_data[\"input\"].to_list()\n",
    "# This is a comment explaining the code\n",
    "arabic=new_data[\"target\"].to_list()\n",
    "\n",
    "# This is a comment explaining the code\n",
    "print(english[:15])\n",
    "\n",
    "# This is a comment explaining the code\n",
    "print(arabic[:15])\n",
    "\n",
    "# This is a comment explaining the code\n",
    "from sklearn.model_selection import train_test_split\n",
    "# This is a comment explaining the code\n",
    "X_train,X_test,y_train,y_test=train_test_split(english,arabic,test_size=0.2)\n",
    "\n",
    "# This is a comment explaining the code\n",
    "len(X_train)\n",
    "\n",
    "# This is a comment explaining the code\n",
    "X_train[:10]\n",
    "\n",
    "# This is a comment explaining the code\n",
    "X_test[:2]\n",
    "\n",
    "# This is a comment explaining the code\n",
    "len(english),len(arabic)\n",
    "\n",
    "# This is a comment explaining the code\n",
    "len(X_train),len(X_test),len(y_train),len(y_test)\n",
    "\n",
    "# This is a comment explaining the code\n",
    "tokenizer=Tokenizer()\n",
    "# This is a comment explaining the code\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# This is a comment explaining the code\n",
    "encoder_vocab=tokenizer.word_index\n",
    "# encoder_vocab\n",
    "\n",
    "# This is a comment explaining the code\n",
    "encoder_vocab_size=len(encoder_vocab)\n",
    "# This is a comment explaining the code\n",
    "encoder_vocab_size\n",
    "\n",
    "# This is a comment explaining the code\n",
    "X_train_tokens=tokenizer.texts_to_sequences(X_train)\n",
    "# This is a comment explaining the code\n",
    "X_test_tokens=tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# This is a comment explaining the code\n",
    "X=X_train_tokens+X_test_tokens\n",
    "\n",
    "# This is a comment explaining the code\n",
    "len(X)\n",
    "\n",
    "# This is a comment explaining the code\n",
    "np.array(X_train_tokens[:1]).shape\n",
    "\n",
    "# This is a comment explaining the code\n",
    "X[:10]\n",
    "\n",
    "# This is a comment explaining the code\n",
    "max_input_length=max([len(i) for i in X])\n",
    "# This is a comment explaining the code\n",
    "max_input_length\n",
    "\n",
    "# This is a comment explaining the code\n",
    "tokenizer_decoder=Tokenizer()\n",
    "# This is a comment explaining the code\n",
    "tokenizer_decoder.fit_on_texts(y_train)\n",
    "\n",
    "# This is a comment explaining the code\n",
    "decoder_vacab=tokenizer_decoder.word_index\n",
    "\n",
    "# This is a comment explaining the code\n",
    "decoder_vacab_size=len(decoder_vacab)+1\n",
    "# This is a comment explaining the code\n",
    "decoder_vacab_size\n",
    "\n",
    "# This is a comment explaining the code\n",
    "y_train_tokens=tokenizer_decoder.texts_to_sequences(y_train)\n",
    "# This is a comment explaining the code\n",
    "y_test_tokens=tokenizer_decoder.texts_to_sequences(y_test)\n",
    "\n",
    "# This is a comment explaining the code\n",
    "y=y_train_tokens+y_test_tokens\n",
    "\n",
    "# This is a comment explaining the code\n",
    "decoder_int_vacab={idx:word for word,idx in decoder_vacab.items()}\n",
    "\n",
    "# This is a comment explaining the code\n",
    "for i in y[0]:\n",
    "# This is a comment explaining the code\n",
    "  print(decoder_int_vacab[i],i)\n",
    "\n",
    "# This is a comment explaining the code\n",
    "decoder_input,decoder_output=[],[]\n",
    "# This is a comment explaining the code\n",
    "for i in y:\n",
    "# This is a comment explaining the code\n",
    "  decoder_input.append(i[:-1])\n",
    "# This is a comment explaining the code\n",
    "  decoder_output.append(i[1:])\n",
    "\n",
    "# This is a comment explaining the code\n",
    "max_target_length=max([len(i) for i in y])\n",
    "# This is a comment explaining the code\n",
    "max_target_length\n",
    "\n",
    "# pad sequences\n",
    "# This is a comment explaining the code\n",
    "encoder_input_seqs=pad_sequences(X,maxlen=max_input_length,padding=\"pre\")\n",
    "# This is a comment explaining the code\n",
    "decoder_input_seqs=pad_sequences(decoder_input,maxlen=max_target_length,padding=\"post\")\n",
    "# This is a comment explaining the code\n",
    "decoder_output_seqs=pad_sequences(decoder_output,maxlen=max_target_length,padding=\"post\")\n",
    "\n",
    "# This is a comment explaining the code\n",
    "encoder_input_seqs.shape\n",
    "\n",
    "# This is a comment explaining the code\n",
    "decoder_input_seqs[0]\n",
    "\n",
    "# This is a comment explaining the code\n",
    "decoder_output_seqs[0]\n",
    "\n",
    "# This is a comment explaining the code\n",
    "decoder_output_seqs.shape\n",
    "\n",
    "# This is a comment explaining the code\n",
    "decoder_input_seqs[:2]\n",
    "\n",
    "# This is a comment explaining the code\n",
    "decoder_output_seqs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pe8tgwmcljH"
   },
   "source": [
    "We Are Ready to build Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4458e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a comment explaining the code\n",
    "decoder_vacab_size\n",
    "\n",
    "# This is a comment explaining the code\n",
    "encoder_input_layer=Input(shape=(None,))\n",
    "# This is a comment explaining the code\n",
    "encoder_embedd=Embedding(encoder_vocab_size,256)(encoder_input_layer)\n",
    "# This is a comment explaining the code\n",
    "_,state_h,state_c=encoder_lstm=LSTM(256,return_state=True)(encoder_embedd)\n",
    "# This is a comment explaining the code\n",
    "encoder_states=[state_h,state_c]\n",
    "\n",
    "# This is a comment explaining the code\n",
    "decoder_input_layer=Input(shape=(None,))\n",
    "# This is a comment explaining the code\n",
    "decoder_embedd=Embedding(decoder_vacab_size,256)(decoder_input_layer)\n",
    "# This is a comment explaining the code\n",
    "decoder_lstm=LSTM(256,return_sequences=True)(decoder_embedd,initial_state=encoder_states)\n",
    "# This is a comment explaining the code\n",
    "decoder_outputs=Dense(decoder_vacab_size+1,activation=\"softmax\")(decoder_lstm)\n",
    "\n",
    "# This is a comment explaining the code\n",
    "model_eng2ar=Model([encoder_input_layer,decoder_input_layer],decoder_outputs)\n",
    "# This is a comment explaining the code\n",
    "model_eng2ar.summary()\n",
    "\n",
    "# model_eng2ar.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\")\n",
    "\n",
    "# This is a comment explaining the code\n",
    "encoder_input_seqs.shape\n",
    "\n",
    "# This is a comment explaining the code\n",
    "decoder_input_seqs.shape,decoder_output_seqs.shape\n",
    "\n",
    "# This is a comment explaining the code\n",
    "BATCH_SIZE = 64\n",
    "# This is a comment explaining the code\n",
    "EPOCHS = 200\n",
    "# This is a comment explaining the code\n",
    "loss = tf.losses.SparseCategoricalCrossentropy()\n",
    "# This is a comment explaining the code\n",
    "model_eng2ar.compile(optimizer='rmsprop', loss=loss, metrics=['accuracy'])\n",
    "# This is a comment explaining the code\n",
    "model_eng2ar.fit([encoder_input_seqs, decoder_input_seqs], decoder_output_seqs,\n",
    "# This is a comment explaining the code\n",
    "          batch_size=BATCH_SIZE,\n",
    "# This is a comment explaining the code\n",
    "          epochs=EPOCHS)\n",
    "\n",
    "# This is a comment explaining the code\n",
    "decoder_vacab_size\n",
    "\n",
    "# This is a comment explaining the code\n",
    "model_eng2ar.save(\"eng2ara.h5\")\n",
    "\n",
    "\n",
    "# Inference function for the model\n",
    "def infer(model, input_text):\n",
    "    \"\"\"This function performs inference using the trained model.\"\"\"\n",
    "    # Preprocess the input text\n",
    "    preprocessed_text = preprocess(input_text)\n",
    "    # Perform the translation\n",
    "    translation = model.translate(preprocessed_text)\n",
    "    # Postprocess the translation\n",
    "    result = postprocess(translation)\n",
    "    return result\n",
    "\n",
    "# Example usage of the inference function\n",
    "# model = load_model('path_to_trained_model')\n",
    "# input_text = \"Hello, how are you?\"\n",
    "# print(infer(model, input_text))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
